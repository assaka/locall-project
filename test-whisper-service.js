// Test for the new Whisper-focused transcription service
import { WhisperTranscriptionService } from './src/lib/whisper-transcription-service.js';

async function testWhisperService() {
  console.log('ğŸ¤ Testing Whisper Transcription Service...');
  
  // Test with a mock audio URL (this would normally be a real audio file)
  const mockAudioUrl = 'https://example.com/test-audio.mp3';
  
  try {
    console.log('ğŸ“¥ Starting transcription test...');
    
    // This will fall back to mock data since we don't have a real audio file
    process.env.NODE_ENV = 'development';
    
    const result = await WhisperTranscriptionService.transcribeAudio(mockAudioUrl);
    
    console.log('âœ… Whisper transcription test successful!');
    console.log('ğŸ“ Transcription:', result.text);
    console.log('ğŸŒ Language:', result.language);
    console.log('â±ï¸  Duration:', result.duration + 's');
    console.log('ğŸ¯ Confidence:', (result.confidence * 100).toFixed(1) + '%');
    console.log('ğŸ“Š Segments:', result.segments.length);
    
    // Test the segments
    if (result.segments.length > 0) {
      console.log('\nğŸ“‹ Sample segments:');
      result.segments.slice(0, 3).forEach((seg, i) => {
        console.log(`  ${i + 1}. [${seg.start}s-${seg.end}s] "${seg.text}" (${(seg.confidence * 100).toFixed(1)}%)`);
      });
    }
    
    return { success: true, result };
    
  } catch (error) {
    console.log('âŒ Whisper test failed:', error.message);
    return { success: false, error: error.message };
  }
}

// Run the test
testWhisperService().then(result => {
  if (result.success) {
    console.log('\nğŸ‰ Whisper service is ready for production!');
    console.log('ğŸ’¡ To use with real audio, add OPENAI_API_KEY to your .env file');
  } else {
    console.log('\nâš ï¸  Test failed, check configuration');
  }
});
